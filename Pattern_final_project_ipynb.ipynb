{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azRTiZYveCsk",
        "outputId": "b4ff7b22-bdc8-4f8e-ad8f-219253ee3a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (12.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision pandas pillow tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZerAb_CgfMcZ",
        "outputId": "b9cbfe1b-6974-47c5-d5f4-938b9379fe7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paste this into a Colab cell (after drive.mount('/content/drive'))\n",
        "# train_severstal_unet_auto_find.py (run in Colab)\n",
        "import os, sys, glob, time\n",
        "import numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# -----------------------\n",
        "# USER: set the top-level folder you gave earlier (do NOT add train.csv)\n",
        "# -----------------------\n",
        "TOP_ROOT = r\"/content/drive/MyDrive/Pttern Assignments/Severstal Kaggle dataset/severstal-steel-defect-detection (1)\"\n",
        "\n",
        "# -----------------------\n",
        "# Utility: find files / image dir recursively\n",
        "# -----------------------\n",
        "def find_file_recursive(root, filename):\n",
        "    matches = glob.glob(os.path.join(root, \"**\", filename), recursive=True)\n",
        "    return matches[0] if len(matches) > 0 else None\n",
        "\n",
        "def find_image_dir_recursive(root):\n",
        "    # prefer commonly named folders\n",
        "    for cand in [\"train_images\", \"train\", \"images\", \"train_images_1600x256\"]:\n",
        "        p = find_file_recursive(root, \"\")  # noop to keep style\n",
        "    # search for any folder that contains jpg files\n",
        "    jpgs = glob.glob(os.path.join(root, \"**\", \"*.jpg\"), recursive=True)\n",
        "    if len(jpgs) == 0:\n",
        "        return None\n",
        "    # return the directory containing the first .jpg found\n",
        "    return os.path.dirname(jpgs[0])\n",
        "\n",
        "# -----------------------\n",
        "# locate train.csv and images\n",
        "# -----------------------\n",
        "train_csv_path = find_file_recursive(TOP_ROOT, \"train.csv\")\n",
        "img_dir = find_image_dir_recursive(TOP_ROOT)\n",
        "\n",
        "print(\"TOP_ROOT:\", TOP_ROOT)\n",
        "print(\"Found train.csv:\", train_csv_path)\n",
        "print(\"Detected image directory:\", img_dir)\n",
        "\n",
        "if train_csv_path is None:\n",
        "    print(\"\\nERROR: train.csv not found under TOP_ROOT. Please confirm where you extracted the Kaggle zip.\")\n",
        "    print(\"You can list files with: !ls -la '{}'\".format(TOP_ROOT))\n",
        "    raise SystemExit(1)\n",
        "if img_dir is None:\n",
        "    print(\"\\nERROR: No .jpg images found under TOP_ROOT. Please confirm image folder exists.\")\n",
        "    raise SystemExit(1)\n",
        "\n",
        "# -----------------------\n",
        "# The rest is the same pipeline: RLE decode, dataset, UNet, training loop\n",
        "# (trimmed for brevity here; full code present below)\n",
        "# -----------------------\n",
        "\n",
        "# --- RLE decode + build_mask_for_image ---\n",
        "def rle_decode(mask_rle, shape):\n",
        "    h, w = shape\n",
        "    if not isinstance(mask_rle, str):\n",
        "        return np.zeros((h, w), dtype=np.uint8)\n",
        "    s = mask_rle.strip().split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n",
        "    starts -= 1\n",
        "    mask = np.zeros(h * w, dtype=np.uint8)\n",
        "    for st, le in zip(starts, lengths):\n",
        "        mask[st:st + le] = 1\n",
        "    mask = mask.reshape((w, h)).T\n",
        "    return mask\n",
        "\n",
        "def build_mask_for_image(image_id, df, shape):\n",
        "    h, w = shape\n",
        "    mask_multi = np.zeros((4, h, w), dtype=np.uint8)\n",
        "    rows = df[df[\"ImageId\"] == image_id]\n",
        "    for _, row in rows.iterrows():\n",
        "        class_id = int(row[\"ClassId\"]) - 1\n",
        "        rle = row[\"EncodedPixels\"]\n",
        "        if isinstance(rle, str):\n",
        "            mask = rle_decode(rle, (h, w))\n",
        "            mask_multi[class_id] = np.maximum(mask_multi[class_id], mask)\n",
        "    return mask_multi\n",
        "\n",
        "# --- Dataset ---\n",
        "class SeverstalDataset(Dataset):\n",
        "    def __init__(self, csv_path, img_dir, transforms=None, mode=\"train\", img_size=(256,512)):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        if \"ImageId_ClassId\" in self.df.columns:\n",
        "            s = self.df[\"ImageId_ClassId\"].str.split(\"_\", expand=True)\n",
        "            self.df[\"ImageId\"] = s[0]; self.df[\"ClassId\"] = s[1]\n",
        "            self.df = self.df[[\"ImageId\",\"ClassId\",\"EncodedPixels\"]]\n",
        "        self.image_ids = sorted(self.df[\"ImageId\"].unique())\n",
        "        n = len(self.image_ids)\n",
        "        if mode==\"train\": self.image_ids = self.image_ids[:int(n*0.9)]\n",
        "        else: self.image_ids = self.image_ids[int(n*0.9):]\n",
        "        self.img_dir = img_dir\n",
        "        self.transforms = transforms\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __len__(self): return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.image_ids[idx]\n",
        "        path = os.path.join(self.img_dir, image_id)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        w,h = img.size\n",
        "        mask_multi = build_mask_for_image(image_id, self.df, (h,w))\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "            # resize masks with nearest\n",
        "            mask_pil = Image.fromarray(np.transpose(mask_multi,(1,2,0)))\n",
        "            mask_pil = mask_pil.resize((self.img_size[1], self.img_size[0]), resample=Image.NEAREST)\n",
        "            mask_arr = np.array(mask_pil); mask_arr = np.transpose(mask_arr,(2,0,1))\n",
        "            mask_tensor = torch.from_numpy(mask_arr.astype(np.float32))\n",
        "        else:\n",
        "            img = T.ToTensor()(img)\n",
        "            mask_tensor = torch.from_numpy(mask_multi.astype(np.float32))\n",
        "        return img, mask_tensor, image_id\n",
        "\n",
        "# --- UNet (simple) ---\n",
        "def conv_block(in_ch, out_ch):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(out_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(out_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=4, features=[64,128,256,512]):\n",
        "        super().__init__()\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.downs = nn.ModuleList()\n",
        "        prev = n_channels\n",
        "        for f in features:\n",
        "            self.downs.append(conv_block(prev,f)); prev=f\n",
        "        self.bottleneck = conv_block(prev, prev*2)\n",
        "        self.ups = nn.ModuleList()\n",
        "        rev = features[::-1]\n",
        "        up_in = prev*2\n",
        "        for f in rev:\n",
        "            self.ups.append(nn.ConvTranspose2d(up_in, f, kernel_size=2, stride=2))\n",
        "            self.ups.append(conv_block(up_in, f))\n",
        "            up_in = f\n",
        "        self.final_conv = nn.Conv2d(features[0], n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        skips=[]\n",
        "        for d in self.downs:\n",
        "            x=d(x); skips.append(x); x=self.pool(x)\n",
        "        x=self.bottleneck(x)\n",
        "        skips=skips[::-1]; up_idx=0\n",
        "        for i in range(0,len(self.ups),2):\n",
        "            up_conv=self.ups[i]; conv=self.ups[i+1]\n",
        "            x=up_conv(x); skip=skips[up_idx]; up_idx+=1\n",
        "            if x.shape!=skip.shape:\n",
        "                x = nn.functional.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=False)\n",
        "            x=torch.cat((skip,x), dim=1); x=conv(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# --- losses & metrics ---\n",
        "def dice_loss_logits(inputs, targets, eps=1e-6):\n",
        "    probs = torch.sigmoid(inputs)\n",
        "    num = 2*(probs*targets).sum(dim=(2,3))\n",
        "    den = probs.sum(dim=(2,3)) + targets.sum(dim=(2,3)) + eps\n",
        "    return (1 - (num/den)).mean()\n",
        "\n",
        "def bce_dice_loss(inputs, targets, bce_weight=0.5):\n",
        "    bce = nn.BCEWithLogitsLoss()(inputs, targets)\n",
        "    d = dice_loss_logits(inputs, targets)\n",
        "    return bce_weight*bce + (1-bce_weight)*d\n",
        "\n",
        "def compute_iou(inputs, targets, thresh=0.5, eps=1e-6):\n",
        "    probs = torch.sigmoid(inputs); preds = (probs>thresh).float()\n",
        "    intersection = (preds*targets).sum(dim=(2,3))\n",
        "    union = (preds+targets - preds*targets).sum(dim=(2,3)) + eps\n",
        "    return (intersection/union).mean().item()\n",
        "\n",
        "# --- training / validation loops ---\n",
        "def train_one_epoch(model, loader, optimizer, device):\n",
        "    model.train(); total_loss=0.0; total_iou=0.0; n=0\n",
        "    for imgs,masks,_ in loader:\n",
        "        imgs=imgs.to(device); masks=masks.to(device)\n",
        "        logits = model(imgs); loss = bce_dice_loss(logits, masks)\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "        iou = compute_iou(logits.detach(), masks.detach())\n",
        "        bs = imgs.size(0)\n",
        "        total_loss += loss.item()*bs; total_iou += iou*bs; n += bs\n",
        "    return total_loss/n, total_iou/n\n",
        "\n",
        "def validate(model, loader, device):\n",
        "    model.eval(); total_loss=0.0; total_iou=0.0; n=0\n",
        "    with torch.no_grad():\n",
        "        for imgs,masks,_ in loader:\n",
        "            imgs=imgs.to(device); masks=masks.to(device)\n",
        "            logits = model(imgs); loss = bce_dice_loss(logits, masks)\n",
        "            iou = compute_iou(logits, masks)\n",
        "            bs = imgs.size(0)\n",
        "            total_loss += loss.item()*bs; total_iou += iou*bs; n+=bs\n",
        "    return total_loss/n, total_iou/n\n",
        "\n",
        "# -----------------------\n",
        "# hyperparams\n",
        "# -----------------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "IMG_SIZE = (256,512)\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 8\n",
        "LR = 1e-3\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# -----------------------\n",
        "# build dataloaders & model\n",
        "# -----------------------\n",
        "transforms = T.Compose([T.Resize((IMG_SIZE[0], IMG_SIZE[1])), T.ToTensor()])\n",
        "train_ds = SeverstalDataset(train_csv_path, img_dir, transforms=transforms, mode=\"train\", img_size=IMG_SIZE)\n",
        "val_ds   = SeverstalDataset(train_csv_path, img_dir, transforms=transforms, mode=\"val\",   img_size=IMG_SIZE)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "model = UNet(n_channels=3, n_classes=4).to(DEVICE)\n",
        "opt = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "best_iou=0.0\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    t0=time.time()\n",
        "    tr_loss, tr_iou = train_one_epoch(model, train_loader, opt, DEVICE)\n",
        "    val_loss, val_iou = validate(model, val_loader, DEVICE)\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | TrainLoss {tr_loss:.4f} IoU {tr_iou:.4f} | ValLoss {val_loss:.4f} IoU {val_iou:.4f} | Time {time.time()-t0:.1f}s\")\n",
        "    if val_iou > best_iou:\n",
        "        best_iou = val_iou\n",
        "        torch.save(model.state_dict(), \"/content/best_unet.pth\")\n",
        "        print(\"Saved best model to /content/best_unet.pth\")\n",
        "\n",
        "print(\"Done. Best Val IoU:\", best_iou)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "NcbC4Xkvfh30",
        "outputId": "70bcf256-6b0a-4a68-83a7-fe7403ec4903"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOP_ROOT: /content/drive/MyDrive/Pttern Assignments/Severstal Kaggle dataset/severstal-steel-defect-detection (1)\n",
            "Found train.csv: None\n",
            "Detected image directory: /content/drive/MyDrive/Pttern Assignments/Severstal Kaggle dataset/severstal-steel-defect-detection (1)/test_images\n",
            "\n",
            "ERROR: train.csv not found under TOP_ROOT. Please confirm where you extracted the Kaggle zip.\n",
            "You can list files with: !ls -la '/content/drive/MyDrive/Pttern Assignments/Severstal Kaggle dataset/severstal-steel-defect-detection (1)'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "1",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        }
      ]
    }
  ]
}